{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import streamlit as st\n",
    "\n",
    "@st.cache_resource\n",
    "def install_packages():\n",
    "    packages = [\n",
    "        \"certifi\",\n",
    "        \"charset-normalizer\",\n",
    "        \"faiss-cpu\",\n",
    "        \"idna\",\n",
    "        \"numpy\",\n",
    "        \"packaging\",\n",
    "        \"python-dotenv\",\n",
    "        \"requests\",\n",
    "        \"urllib3\",\n",
    "        \"pyarrow\",\n",
    "        \"PyPDF2\",\n",
    "        \"python-docx\",\n",
    "        \"spacy\"\n",
    "    ]\n",
    "\n",
    "    progress_bar = st.progress(0, text=\"Setting up the application...\")\n",
    "    total = len(packages)\n",
    "    for i, package in enumerate(packages, start=1):\n",
    "        progress_bar.progress(int((i - 1) / total * 100), text=f\"Setting up step {i} of {total}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        except subprocess.CalledProcessError:\n",
    "            st.error(\"Something went wrong while setting things up. Please try again or contact support.\")\n",
    "            break\n",
    "        progress_bar.progress(int(i / total * 100), text=f\"Finished step {i} of {total}\")\n",
    "    progress_bar.progress(100, text=\"Setup complete\")\n",
    "    st.success(\"You're all set!\")\n",
    "    return True\n",
    "\n",
    "install_packages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e011114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "import re\n",
    "import builtins\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "from cli_app import (\n",
    "    load_input_text,\n",
    "    extract_questions,\n",
    "    build_docx,\n",
    ")\n",
    "from qa_core import answer_question\n",
    "from answer_composer import CompletionsClient, get_openai_completion\n",
    "from input_file_reader.interpreter_sheet import collect_non_empty_cells\n",
    "from rfp_xlsx_slot_finder import ask_sheet_schema\n",
    "from rfp_xlsx_apply_answers import write_excel_answers\n",
    "from rfp_docx_slot_finder import extract_slots_from_docx\n",
    "from rfp_docx_apply_answers import apply_answers_to_docx\n",
    "MODEL_OPTIONS = [\n",
    "    \"gpt-4.1-nano-2025-04-14_research\",\n",
    "    \"o3-2025-04-16_research\",\n",
    "]\n",
    "FEEDBACK_FILE = \"feedback.xlsx\"\n",
    "\n",
    "\n",
    "def load_fund_tags() -> List[str]:\n",
    "    path = Path('~/derivs-tool/rfp-ai-tool/structured_extraction/embedding_data.json').expanduser()\n",
    "    try:\n",
    "        with path.open('r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except Exception:\n",
    "        return []\n",
    "    tags = {t for item in data for t in item.get('metadata', {}).get('tags', [])}\n",
    "    return sorted(tags)\n",
    "\n",
    "\n",
    "class OpenAIClient:\n",
    "    def __init__(self, model: str):\n",
    "        self.model = model\n",
    "\n",
    "    def get_completion(self, prompt: str, json_output: bool = False):\n",
    "        return get_openai_completion(prompt, self.model, json_output=json_output)\n",
    "\n",
    "\n",
    "def save_uploaded_file(uploaded_file) -> str:\n",
    "    suffix = Path(uploaded_file.name).suffix\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)\n",
    "    tmp.write(uploaded_file.read())\n",
    "    tmp.flush()\n",
    "    return tmp.name\n",
    "\n",
    "def save_feedback(rating, reason, other, dev_logs, log_text):\n",
    "    entry = [\n",
    "        datetime.utcnow().isoformat(),\n",
    "        rating,\n",
    "        reason,\n",
    "        other,\n",
    "        \"\n",
    "\".join(dev_logs),\n",
    "        log_text,\n",
    "    ]\n",
    "    if os.path.exists(FEEDBACK_FILE):\n",
    "        wb = load_workbook(FEEDBACK_FILE)\n",
    "        ws = wb.active\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.append([\"timestamp\", \"rating\", \"reason\", \"other\", \"dev_logs\", \"log_text\"])\n",
    "    ws.append(entry)\n",
    "    wb.save(FEEDBACK_FILE)\n",
    "\n",
    "\n",
    "def build_generator(\n",
    "    search_mode: str,\n",
    "    fund: Optional[str],\n",
    "    k: int,\n",
    "    length: Optional[str],\n",
    "    approx_words: Optional[int],\n",
    "    min_confidence: float,\n",
    "    include_citations: bool,\n",
    "    llm,\n",
    "    extra_docs: Optional[List[str]] = None,\n",
    "):\n",
    "    def gen(question: str):\n",
    "        ans, cmts = answer_question(\n",
    "            question,\n",
    "            search_mode,\n",
    "            fund,\n",
    "            k,\n",
    "            length,\n",
    "            approx_words,\n",
    "            min_confidence,\n",
    "            llm,\n",
    "            extra_docs=extra_docs,\n",
    "        )\n",
    "        if not include_citations:\n",
    "            ans = re.sub(r\"\\[\\d+\\]\", \"\", ans)\n",
    "            return ans\n",
    "        citations = {\n",
    "            lbl: {\"text\": snippet, \"source_file\": src}\n",
    "            for lbl, src, snippet, score, date in cmts\n",
    "        }\n",
    "        return {\"text\": ans, \"citations\": citations}\n",
    "\n",
    "    return gen\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.title(\"RFP Responder\")\n",
    "    view_mode = st.sidebar.radio(\"Interface mode\", [\"User\", \"Developer\"], index=0)\n",
    "\n",
    "    framework_env = os.getenv(\"ANSWER_FRAMEWORK\")\n",
    "    if framework_env:\n",
    "        if view_mode == \"Developer\":\n",
    "            st.info(f\"Using framework from ANSWER_FRAMEWORK: {framework_env}\")\n",
    "        framework = framework_env\n",
    "    else:\n",
    "        framework = st.selectbox(\"Framework\", [\"aladdin\", \"openai\"], index=0, help=\"Choose backend for language model.\")\n",
    "\n",
    "    if framework == \"aladdin\":\n",
    "        for key, label in [\n",
    "            (\"aladdin_studio_api_key\", \"Aladdin Studio API key\"),\n",
    "            (\"defaultWebServer\", \"Default Web Server\"),\n",
    "            (\"aladdin_user\", \"Aladdin user\"),\n",
    "            (\"aladdin_passwd\", \"Aladdin password\"),\n",
    "        ]:\n",
    "            if os.getenv(key):\n",
    "                if view_mode == \"Developer\":\n",
    "                    st.info(f\"{key} loaded from environment\")\n",
    "            else:\n",
    "                val = st.text_input(label, type=\"password\" if \"passwd\" in key or \"api_key\" in key else \"default\")\n",
    "                if val:\n",
    "                    os.environ[key] = val\n",
    "    else:\n",
    "        if os.getenv(\"OPENAI_API_KEY\"):\n",
    "            if view_mode == \"Developer\":\n",
    "                st.info(\"OPENAI_API_KEY loaded from environment\")\n",
    "        else:\n",
    "            api_key = st.text_input(\"OpenAI API key\", type=\"password\", help=\"API key for OpenAI.\")\n",
    "            if api_key:\n",
    "                os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    uploaded = st.file_uploader(\n",
    "        \"Upload document\",\n",
    "        type=[\"pdf\", \"docx\", \"txt\", \"xlsx\"],\n",
    "        help=\"Upload the RFP or question file.\",\n",
    "    )\n",
    "\n",
    "    if view_mode == \"Developer\":\n",
    "        st.info(\"Search mode fixed to 'both'\")\n",
    "        search_mode = \"both\"\n",
    "        fund = st.selectbox(\n",
    "            \"Fund\", [\"\"] + load_fund_tags(), index=0,\n",
    "            help=\"Filter answers for a specific fund or strategy.\",\n",
    "        )\n",
    "        llm_model = st.selectbox(\n",
    "            \"LLM model\",\n",
    "            MODEL_OPTIONS,\n",
    "            index=0,\n",
    "            help=\"Model name for generating answers.\",\n",
    "        )\n",
    "        k_max_hits = st.number_input(\"Hits per question\", value=20, help=\"Maximum documents retrieved per question.\")\n",
    "        length_opt = st.selectbox(\"Answer length\", [\"auto\", \"short\", \"medium\", \"long\"], index=0)\n",
    "        approx_words = st.text_input(\"Approx words\", value=\"\", help=\"Approximate words per answer (optional).\")\n",
    "        min_confidence = st.number_input(\"Min confidence\", value=0.0, help=\"Minimum score for retrieved documents.\")\n",
    "        include_env = os.getenv(\"RFP_INCLUDE_COMMENTS\")\n",
    "        if include_env is not None:\n",
    "            include_citations = include_env != \"0\"\n",
    "            st.info(f\"Using include citations from RFP_INCLUDE_COMMENTS: {include_citations}\")\n",
    "        else:\n",
    "            include_citations = st.checkbox(\"Include citations with comments\", value=True)\n",
    "        docx_as_text = st.checkbox(\"Treat DOCX as text\", value=False)\n",
    "        docx_write_mode = st.selectbox(\"DOCX write mode\", [\"fill\", \"replace\", \"append\"], index=0)\n",
    "        extra_uploads = st.file_uploader(\n",
    "            \"Additional documents\", type=[\"pdf\", \"docx\", \"txt\"], accept_multiple_files=True\n",
    "        )\n",
    "    else:\n",
    "        st.markdown(\"### Settings\")\n",
    "        search_mode = \"both\"\n",
    "        fund = st.selectbox(\n",
    "            \"Fund\", [\"\"] + load_fund_tags(), index=0,\n",
    "            help=\"Select fund or strategy context for better answers.\",\n",
    "        )\n",
    "        llm_model = MODEL_OPTIONS[0]\n",
    "        k_max_hits = 20\n",
    "        length_opt = st.selectbox(\n",
    "            \"Answer length\", [\"auto\", \"short\", \"medium\", \"long\"], index=0,\n",
    "            help=\"Controls how verbose the answer is; 'auto' lets the model decide based on sources.\",\n",
    "        )\n",
    "        approx_words = st.text_input(\"Approx words\", value=\"\", help=\"Optional target word count for answers.\")\n",
    "        min_confidence = 0.0\n",
    "        include_citations = st.checkbox(\n",
    "            \"Include citations\", value=True,\n",
    "            help=\"Attach source references to answers.\",\n",
    "        )\n",
    "        docx_as_text = False\n",
    "        docx_write_mode = \"fill\"\n",
    "        extra_uploads = None\n",
    "\n",
    "    show_live = st.checkbox(\"Show questions and answers during processing\", value=False)\n",
    "    if \"output_files\" not in st.session_state:\n",
    "        st.session_state[\"output_files\"] = None\n",
    "    run_clicked = st.button(\"Run\")\n",
    "    if run_clicked and uploaded is not None and fund:\n",
    "        phase_placeholder = st.empty()\n",
    "        sub_placeholder = st.empty()\n",
    "        dev_placeholder = st.empty()\n",
    "        dev_logs = []\n",
    "        log_messages = []\n",
    "        original_print = builtins.print\n",
    "        def capture_print(*args, **kwargs):\n",
    "            original_print(*args, **kwargs)\n",
    "            log_messages.append(\" \".join(str(a) for a in args))\n",
    "        builtins.print = capture_print\n",
    "        current_phase = None\n",
    "        suffix = Path(uploaded.name).suffix.lower()\n",
    "        base_steps = 1\n",
    "        if suffix in (\".xlsx\", \".xls\"):\n",
    "            branch_steps = 4\n",
    "        elif suffix == \".docx\" and not docx_as_text:\n",
    "            branch_steps = 3\n",
    "        else:\n",
    "            branch_steps = 3\n",
    "        total_steps = base_steps + branch_steps + 1\n",
    "        step_bar = st.progress(0)\n",
    "        step_count = 0\n",
    "        def log_step(dev_msg, user_msg=None):\n",
    "            nonlocal step_count, current_phase\n",
    "            if user_msg and user_msg != current_phase:\n",
    "                current_phase = user_msg\n",
    "                phase_placeholder.markdown(f\"**{current_phase}**\")\n",
    "                sub_placeholder.empty()\n",
    "            sub_placeholder.markdown(dev_msg)\n",
    "            if view_mode == \"Developer\":\n",
    "                dev_logs.append(f\"{current_phase}: {dev_msg}\")\n",
    "                dev_placeholder.markdown(\"\\n\".join(f\"{i+1}. {m}\" for i, m in enumerate(dev_logs)))\n",
    "            step_count += 1\n",
    "            step_bar.progress(step_count / total_steps, text=current_phase)\n",
    "        log_step(\"Saving uploaded file\", \"Preparing document...\")\n",
    "        input_path = save_uploaded_file(uploaded)\n",
    "        extra_docs = [save_uploaded_file(f) for f in extra_uploads] if extra_uploads else None\n",
    "        llm = CompletionsClient(model=llm_model) if framework == \"aladdin\" else OpenAIClient(model=llm_model)\n",
    "        if suffix in (\".xlsx\", \".xls\"):\n",
    "            log_step(\"Collecting non-empty cells\", \"Reading workbook...\")\n",
    "            cells = collect_non_empty_cells(input_path)\n",
    "            log_step(\"Inferring sheet schema\", \"Analyzing workbook structure...\")\n",
    "            schema = ask_sheet_schema(input_path)\n",
    "            log_step(\"Building answer generator\", \"Preparing answer generator...\")\n",
    "            gen = build_generator(\n",
    "                search_mode,\n",
    "                fund,\n",
    "                int(k_max_hits),\n",
    "                length_opt,\n",
    "                int(approx_words) if approx_words else None,\n",
    "                float(min_confidence),\n",
    "                include_citations,\n",
    "                llm,\n",
    "                extra_docs,\n",
    "            )\n",
    "            log_step(\"Starting question-answering\", \"Generating answers...\")\n",
    "            answers = []\n",
    "            total_qs = len(schema)\n",
    "            progress = st.progress(0)\n",
    "            qa_box = st.container() if show_live else None\n",
    "            for i, entry in enumerate(schema, 1):\n",
    "                question = (entry.get(\"question_text\") or \"\").strip()\n",
    "                if show_live and question:\n",
    "                    qa_box.markdown(f\"**Q{i}:** {question}\")\n",
    "                ans = gen(question)\n",
    "                answers.append(ans)\n",
    "                progress.progress(i / total_qs, text=f\"{i}/{total_qs}\")\n",
    "                if show_live:\n",
    "                    text = ans.get('text', '') if isinstance(ans, dict) else ans\n",
    "                    qa_box.markdown(f\"**A{i}:** {text}\")\n",
    "            out_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".xlsx\")\n",
    "            write_excel_answers(\n",
    "                schema,\n",
    "                answers,\n",
    "                input_path,\n",
    "                out_tmp.name,\n",
    "                include_comments=include_citations,\n",
    "            )\n",
    "            with open(out_tmp.name, \"rb\") as f:\n",
    "                excel_bytes = f.read()\n",
    "            questions = [(entry.get(\"question_text\") or \"\").strip() for entry in schema]\n",
    "            answer_texts = []\n",
    "            comments_list = []\n",
    "            for ans in answers:\n",
    "                if isinstance(ans, dict):\n",
    "                    answer_texts.append(ans.get(\"text\", \"\"))\n",
    "                    cmts = []\n",
    "                    for lbl, meta in sorted(ans.get(\"citations\", {}).items(), key=lambda x: int(x[0])):\n",
    "                        cmts.append((lbl, meta.get(\"source_file\", \"\"), meta.get(\"text\", \"\"), 0.0, \"\"))\n",
    "                    comments_list.append(cmts)\n",
    "                else:\n",
    "                    answer_texts.append(ans)\n",
    "                    comments_list.append([])\n",
    "            qa_doc_bytes = build_docx(questions, answer_texts, comments_list, include_comments=include_citations)\n",
    "            st.session_state[\"output_files\"] = {\n",
    "                \"Download answered workbook\": (excel_bytes, Path(uploaded.name).stem + \"_answered.xlsx\"),\n",
    "                \"Download Q/A report\": (qa_doc_bytes, Path(uploaded.name).stem + \"_answered.docx\"),\n",
    "            }\n",
    "        elif suffix == \".docx\" and not docx_as_text:\n",
    "            log_step(\"Extracting slots from DOCX\", \"Analyzing document...\")\n",
    "            slots_payload = extract_slots_from_docx(input_path)\n",
    "            slots_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".json\")\n",
    "            json.dump(slots_payload, slots_tmp)\n",
    "            slots_tmp.flush()\n",
    "            log_step(\"Building answer generator\", \"Preparing answer generator...\")\n",
    "            gen = build_generator(\n",
    "                search_mode,\n",
    "                fund,\n",
    "                int(k_max_hits),\n",
    "                length_opt,\n",
    "                int(approx_words) if approx_words else None,\n",
    "                float(min_confidence),\n",
    "                include_citations,\n",
    "                llm,\n",
    "                extra_docs,\n",
    "            )\n",
    "            log_step(\"Starting question-answering\", \"Generating answers...\")\n",
    "            answers_dict = {}\n",
    "            slot_list = slots_payload.get('slots', [])\n",
    "            progress = st.progress(0)\n",
    "            qa_box = st.container() if show_live else None\n",
    "            for i, slot in enumerate(slot_list, 1):\n",
    "                question = (slot.get(\"question_text\") or \"\").strip()\n",
    "                if show_live and question:\n",
    "                    qa_box.markdown(f\"**Q{i}:** {question}\")\n",
    "                ans = gen(question)\n",
    "                answers_dict[slot.get('id', f'slot_{i}')] = ans\n",
    "                progress.progress(i / len(slot_list), text=f\"{i}/{len(slot_list)}\")\n",
    "                if show_live:\n",
    "                    text = ans.get('text', '') if isinstance(ans, dict) else ans\n",
    "                    qa_box.markdown(f\"**A{i}:** {text}\")\n",
    "            answers_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".json\")\n",
    "            json.dump({'by_id': answers_dict}, answers_tmp)\n",
    "            answers_tmp.flush()\n",
    "            out_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".docx\")\n",
    "            apply_answers_to_docx(\n",
    "                docx_path=input_path,\n",
    "                slots_json_path=slots_tmp.name,\n",
    "                answers_json_path=answers_tmp.name,\n",
    "                out_path=out_tmp.name,\n",
    "                mode=docx_write_mode,\n",
    "                generator=None,\n",
    "                gen_name=\"streamlit_app:rag_gen\",\n",
    "            )\n",
    "            with open(out_tmp.name, \"rb\") as f:\n",
    "                docx_bytes = f.read()\n",
    "            st.session_state[\"output_files\"] = {\n",
    "                \"Download answered DOCX\": (docx_bytes, Path(uploaded.name).stem + \"_answered.docx\"),\n",
    "            }\n",
    "        else:\n",
    "            log_step(\"Loading input text\", \"Reading document...\")\n",
    "            raw = load_input_text(input_path)\n",
    "            log_step(\"Extracting questions\", \"Finding questions...\")\n",
    "            questions = extract_questions(raw, llm)\n",
    "            log_step(\"Starting question-answering\", \"Generating answers...\")\n",
    "            answers = []\n",
    "            comments = []\n",
    "            total_qs = len(questions)\n",
    "            progress = st.progress(0)\n",
    "            qa_box = st.container() if show_live else None\n",
    "            for i, q in enumerate(questions, 1):\n",
    "                if show_live and q:\n",
    "                    qa_box.markdown(f\"**Q{i}:** {q}\")\n",
    "                ans, cmts = answer_question(\n",
    "                    q,\n",
    "                    search_mode,\n",
    "                    fund,\n",
    "                    int(k_max_hits),\n",
    "                    length_opt,\n",
    "                    int(approx_words) if approx_words else None,\n",
    "                    float(min_confidence),\n",
    "                    llm,\n",
    "                )\n",
    "                if not include_citations:\n",
    "                    ans = re.sub(r\"\\[\\d+\\]\", \"\", ans)\n",
    "                    cmts = []\n",
    "                answers.append(ans)\n",
    "                comments.append(cmts)\n",
    "                progress.progress(i / total_qs, text=f\"{i}/{total_qs}\")\n",
    "                if show_live:\n",
    "                    qa_box.markdown(f\"**A{i}:** {ans}\")\n",
    "            qa_doc = build_docx(\n",
    "                questions,\n",
    "                answers,\n",
    "                comments,\n",
    "                include_comments=include_citations,\n",
    "            )\n",
    "            st.session_state[\"output_files\"] = {\n",
    "                \"Download Q/A report\": (qa_doc, Path(uploaded.name).stem + \"_answered.docx\"),\n",
    "            }\n",
    "        step_bar.progress(1.0, text=\"Done\")\n",
    "        builtins.print = original_print\n",
    "        logs_text = \"\\\\n\".join(log_messages)\n",
    "        st.session_state[\"dev_logs\"] = dev_logs\n",
    "        st.session_state[\"logs_text\"] = logs_text\n",
    "    elif run_clicked and not fund:\n",
    "        st.warning(\"Please select a fund or strategy before running.\")\n",
    "    elif run_clicked:\n",
    "        st.warning(\"Please upload a document before running.\")\n",
    "\n",
    "    if st.session_state.get(\"output_files\"):\n",
    "        for label, (data, fname) in st.session_state[\"output_files\"].items():\n",
    "            st.download_button(label, data, file_name=fname, key=label)\n",
    "        feedback = st.radio(\n",
    "            \"Was the output helpful?\", [\"üëç\", \"üëé\"], index=None, horizontal=True, key=\"feedback\"\n",
    "        )\n",
    "        reason = \"\"\n",
    "        other_feedback = \"\"\n",
    "        if feedback == \"üëé\":\n",
    "            reason = st.selectbox(\n",
    "                \"Why was the result unsatisfactory?\", [\"Inaccurate info\", \"Typo\", \"Other\"], key=\"feedback_reason\"\n",
    "            )\n",
    "            if reason == \"Other\":\n",
    "                other_feedback = st.text_input(\"Please describe the issue\", key=\"feedback_other\")\n",
    "        if feedback and st.button(\"Submit feedback\", key=\"feedback_submit\"):\n",
    "            save_feedback(\n",
    "                feedback,\n",
    "                reason,\n",
    "                other_feedback,\n",
    "                st.session_state.get(\"dev_logs\", []),\n",
    "                st.session_state.get(\"logs_text\", \"\"),\n",
    "            )\n",
    "            st.success(\"Thanks for your feedback!\")\n",
    "        if st.button(\"Reset\", key=\"reset\"):\n",
    "            for key in (\n",
    "                \"output_files\",\n",
    "                \"dev_logs\",\n",
    "                \"logs_text\",\n",
    "                \"feedback\",\n",
    "                \"feedback_reason\",\n",
    "                \"feedback_other\",\n",
    "            ):\n",
    "                st.session_state.pop(key, None)\n",
    "            st.rerun()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
