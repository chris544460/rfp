{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import streamlit as st\n",
    "\n",
    "# Install all packages without specific versions\n",
    "packages = [\n",
    "    \"certifi\",\n",
    "    \"charset-normalizer\",\n",
    "    \"faiss-cpu\",\n",
    "    \"idna\",\n",
    "    \"numpy\",\n",
    "    \"packaging\",\n",
    "    \"python-dotenv\",\n",
    "    \"requests\",\n",
    "    \"urllib3\",\n",
    "    \"pyarrow\",\n",
    "    \"PyPDF2\",\n",
    "    \"python-docx\",\n",
    "    \"spacy\"\n",
    "]\n",
    "\n",
    "progress_bar = st.progress(0, text=\"Setting up the application...\")\n",
    "total = len(packages)\n",
    "for i, package in enumerate(packages, start=1):\n",
    "    progress_bar.progress(int((i - 1) / total * 100), text=f\"Setting up step {i} of {total}...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        st.error(\"Something went wrong while setting things up. Please try again or contact support.\")\n",
    "    progress_bar.progress(int(i / total * 100), text=f\"Finished step {i} of {total}\")\n",
    "progress_bar.progress(100, text=\"Setup complete\")\n",
    "st.success(\"You're all set!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e011114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "from cli_app import (\n",
    "    load_input_text,\n",
    "    extract_questions,\n",
    "    build_docx,\n",
    ")\n",
    "from qa_core import answer_question\n",
    "from answer_composer import CompletionsClient, get_openai_completion\n",
    "from input_file_reader.interpreter_sheet import collect_non_empty_cells\n",
    "from rfp_xlsx_slot_finder import ask_sheet_schema\n",
    "from rfp_xlsx_apply_answers import write_excel_answers\n",
    "from rfp_docx_slot_finder import extract_slots_from_docx\n",
    "from rfp_docx_apply_answers import apply_answers_to_docx\n",
    "\n",
    "\n",
    "class OpenAIClient:\n",
    "    def __init__(self, model: str):\n",
    "        self.model = model\n",
    "\n",
    "    def get_completion(self, prompt: str, json_output: bool = False):\n",
    "        return get_openai_completion(prompt, self.model, json_output=json_output)\n",
    "\n",
    "\n",
    "def save_uploaded_file(uploaded_file) -> str:\n",
    "    suffix = Path(uploaded_file.name).suffix\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)\n",
    "    tmp.write(uploaded_file.read())\n",
    "    tmp.flush()\n",
    "    return tmp.name\n",
    "\n",
    "\n",
    "def build_generator(\n",
    "    search_mode: str,\n",
    "    fund: Optional[str],\n",
    "    k: int,\n",
    "    length: Optional[str],\n",
    "    approx_words: Optional[int],\n",
    "    min_confidence: float,\n",
    "    include_citations: bool,\n",
    "    llm,\n",
    "    extra_docs: Optional[List[str]] = None,\n",
    "):\n",
    "    def gen(question: str):\n",
    "        ans, cmts = answer_question(\n",
    "            question,\n",
    "            search_mode,\n",
    "            fund,\n",
    "            k,\n",
    "            length,\n",
    "            approx_words,\n",
    "            min_confidence,\n",
    "            llm,\n",
    "            extra_docs=extra_docs,\n",
    "        )\n",
    "        if not include_citations:\n",
    "            ans = re.sub(r\"\\[\\d+\\]\", \"\", ans)\n",
    "            return ans\n",
    "        citations = {\n",
    "            lbl: {\"text\": snippet, \"source_file\": src}\n",
    "            for lbl, src, snippet, score, date in cmts\n",
    "        }\n",
    "        return {\"text\": ans, \"citations\": citations}\n",
    "\n",
    "    return gen\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.title(\"RFP Responder\")\n",
    "    framework_env = os.getenv(\"ANSWER_FRAMEWORK\")\n",
    "    if framework_env:\n",
    "        st.info(f\"Using framework from ANSWER_FRAMEWORK: {framework_env}\")\n",
    "        framework = framework_env\n",
    "    else:\n",
    "        framework = st.selectbox(\"Framework\", [\"aladdin\", \"openai\"], index=0)\n",
    "    if framework == \"aladdin\":\n",
    "        for key, label in [\n",
    "            (\"aladdin_studio_api_key\", \"Aladdin Studio API key\"),\n",
    "            (\"defaultWebServer\", \"Default Web Server\"),\n",
    "            (\"aladdin_user\", \"Aladdin user\"),\n",
    "            (\"aladdin_passwd\", \"Aladdin password\"),\n",
    "        ]:\n",
    "            if os.getenv(key):\n",
    "                st.info(f\"{key} loaded from environment\")\n",
    "            else:\n",
    "                val = st.text_input(label, type=\"password\" if \"passwd\" in key or \"api_key\" in key else \"default\")\n",
    "                if val:\n",
    "                    os.environ[key] = val\n",
    "    else:\n",
    "        if os.getenv(\"OPENAI_API_KEY\"):\n",
    "            st.info(\"OPENAI_API_KEY loaded from environment\")\n",
    "        else:\n",
    "            api_key = st.text_input(\"OpenAI API key\", type=\"password\")\n",
    "            if api_key:\n",
    "                os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    uploaded = st.file_uploader(\n",
    "        \"Upload RFP file\", type=[\"pdf\", \"docx\", \"doc\", \"txt\", \"xlsx\", \"xls\"]\n",
    "    )\n",
    "\n",
    "    fund = st.text_input(\"Fund tag filter\") or None\n",
    "    search_mode_env = os.getenv(\"RFP_SEARCH_MODE\")\n",
    "    if search_mode_env:\n",
    "        st.info(f\"Using search mode from RFP_SEARCH_MODE: {search_mode_env}\")\n",
    "        search_mode = search_mode_env\n",
    "    else:\n",
    "        search_mode = st.selectbox(\n",
    "            \"Search mode\", [\"answer\", \"question\", \"blend\", \"dual\", \"both\"], index=3\n",
    "        )\n",
    "    model_env_var = \"ALADDIN_MODEL\" if framework == \"aladdin\" else \"OPENAI_MODEL\"\n",
    "    llm_model_env = os.getenv(model_env_var)\n",
    "    if llm_model_env:\n",
    "        st.info(f\"Using LLM model from {model_env_var}: {llm_model_env}\")\n",
    "        llm_model = llm_model_env\n",
    "    else:\n",
    "        if framework == \"aladdin\":\n",
    "            llm_model = st.selectbox(\"LLM model\", [\"gpt-5-nano\", \"gpt-35-turbo\"], index=0)\n",
    "        else:\n",
    "            llm_model = st.selectbox(\"LLM model\", [\"gpt-4.1-nano-2025-04-14_research\", \"o3-2025-04-16_research\"], index=0)\n",
    "    approx_env = os.getenv(\"RFP_APPROX_WORDS\")\n",
    "    length_env = os.getenv(\"RFP_LENGTH\")\n",
    "    if approx_env:\n",
    "        st.info(f\"Using custom word count from RFP_APPROX_WORDS: {approx_env}\")\n",
    "        length_opt = None\n",
    "        approx_words = int(approx_env)\n",
    "    elif length_env:\n",
    "        st.info(f\"Using preset length from RFP_LENGTH: {length_env}\")\n",
    "        length_opt = length_env\n",
    "        approx_words = None\n",
    "    else:\n",
    "        length_mode = st.radio(\"Answer length mode\", [\"Preset\", \"Custom word count\"])\n",
    "        if length_mode == \"Preset\":\n",
    "            length_opt = st.selectbox(\n",
    "                \"Preset length\", [\"short\", \"medium\", \"long\"], index=1\n",
    "            )\n",
    "            approx_words = None\n",
    "        else:\n",
    "            length_opt = None\n",
    "            approx_words = st.number_input(\n",
    "                \"Approximate word count\", min_value=1, value=150\n",
    "            )\n",
    "    k_env = os.getenv(\"RFP_K\")\n",
    "    if k_env:\n",
    "        st.info(f\"Using hits per question from RFP_K: {k_env}\")\n",
    "        k_max_hits = int(k_env)\n",
    "    else:\n",
    "        k_max_hits = st.number_input(\"Hits per question\", min_value=1, value=6)\n",
    "    min_conf_env = os.getenv(\"RFP_MIN_CONFIDENCE\")\n",
    "    if min_conf_env:\n",
    "        st.info(f\"Using min confidence from RFP_MIN_CONFIDENCE: {min_conf_env}\")\n",
    "        min_confidence = float(min_conf_env)\n",
    "    else:\n",
    "        min_confidence = st.number_input(\"Min confidence\", value=0.0)\n",
    "    include_env = os.getenv(\"RFP_INCLUDE_COMMENTS\")\n",
    "    if include_env is not None:\n",
    "        include_citations = include_env != \"0\"\n",
    "        st.info(f\"Using include citations from RFP_INCLUDE_COMMENTS: {include_citations}\")\n",
    "    else:\n",
    "        include_citations = st.checkbox(\"Include citations with comments\", value=True)\n",
    "    docx_as_text = st.checkbox(\"Treat DOCX as text\", value=False)\n",
    "    docx_write_mode = st.selectbox(\n",
    "        \"DOCX write mode\", [\"fill\", \"replace\", \"append\"], index=0\n",
    "    )\n",
    "\n",
    "    extra_uploads = st.file_uploader(\n",
    "        \"Additional documents\", type=[\"pdf\", \"docx\", \"txt\"], accept_multiple_files=True\n",
    "    )\n",
    "\n",
    "    if st.button(\"Run\") and uploaded is not None:\n",
    "        input_path = save_uploaded_file(uploaded)\n",
    "        extra_docs = [save_uploaded_file(f) for f in extra_uploads] if extra_uploads else None\n",
    "        llm = CompletionsClient(model=llm_model) if framework == \"aladdin\" else OpenAIClient(model=llm_model)\n",
    "        suffix = Path(uploaded.name).suffix.lower()\n",
    "\n",
    "        if suffix in (\".xlsx\", \".xls\"):\n",
    "            cells = collect_non_empty_cells(input_path)\n",
    "            schema = ask_sheet_schema(input_path)\n",
    "            gen = build_generator(\n",
    "                search_mode,\n",
    "                fund,\n",
    "                int(k_max_hits),\n",
    "                length_opt,\n",
    "                int(approx_words) if approx_words else None,\n",
    "                float(min_confidence),\n",
    "                include_citations,\n",
    "                llm,\n",
    "                extra_docs,\n",
    "            )\n",
    "            answers = [gen((entry.get(\"question_text\") or \"\").strip()) for entry in schema]\n",
    "            out_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".xlsx\")\n",
    "            write_excel_answers(\n",
    "                schema,\n",
    "                answers,\n",
    "                input_path,\n",
    "                out_tmp.name,\n",
    "                include_comments=include_citations,\n",
    "            )\n",
    "            with open(out_tmp.name, \"rb\") as f:\n",
    "                st.download_button(\n",
    "                    \"Download answered workbook\",\n",
    "                    f,\n",
    "                    file_name=Path(uploaded.name).stem + \"_answered.xlsx\",\n",
    "                )\n",
    "        elif suffix == \".docx\" and not docx_as_text:\n",
    "            slots = extract_slots_from_docx(input_path)\n",
    "            slots_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".json\")\n",
    "            json.dump(slots, slots_tmp)\n",
    "            slots_tmp.flush()\n",
    "            gen = build_generator(\n",
    "                search_mode,\n",
    "                fund,\n",
    "                int(k_max_hits),\n",
    "                length_opt,\n",
    "                int(approx_words) if approx_words else None,\n",
    "                float(min_confidence),\n",
    "                include_citations,\n",
    "                llm,\n",
    "                extra_docs,\n",
    "            )\n",
    "            out_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".docx\")\n",
    "            apply_answers_to_docx(\n",
    "                docx_path=input_path,\n",
    "                slots_json_path=slots_tmp.name,\n",
    "                answers_json_path=\"\",\n",
    "                out_path=out_tmp.name,\n",
    "                mode=docx_write_mode,\n",
    "                generator=gen,\n",
    "                gen_name=\"streamlit_app:rag_gen\",\n",
    "            )\n",
    "            with open(out_tmp.name, \"rb\") as f:\n",
    "                st.download_button(\n",
    "                    \"Download answered DOCX\",\n",
    "                    f,\n",
    "                    file_name=Path(uploaded.name).stem + \"_answered.docx\",\n",
    "                )\n",
    "        else:\n",
    "            raw = load_input_text(input_path)\n",
    "            questions = extract_questions(raw, llm)\n",
    "            answers = []\n",
    "            comments = []\n",
    "            for q in questions:\n",
    "                ans, cmts = answer_question(\n",
    "                    q,\n",
    "                    search_mode,\n",
    "                    fund,\n",
    "                    int(k_max_hits),\n",
    "                    length_opt,\n",
    "                    int(approx_words) if approx_words else None,\n",
    "                    float(min_confidence),\n",
    "                    llm,\n",
    "                )\n",
    "                if not include_citations:\n",
    "                    ans = re.sub(r\"\\[\\d+\\]\", \"\", ans)\n",
    "                    cmts = []\n",
    "                answers.append(ans)\n",
    "                comments.append(cmts)\n",
    "            qa_doc = build_docx(\n",
    "                questions,\n",
    "                answers,\n",
    "                comments,\n",
    "                include_comments=include_citations,\n",
    "            )\n",
    "            out_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".docx\")\n",
    "            out_tmp.write(qa_doc)\n",
    "            out_tmp.flush()\n",
    "            with open(out_tmp.name, \"rb\") as f:\n",
    "                st.download_button(\n",
    "                    \"Download Q/A report\",\n",
    "                    f,\n",
    "                    file_name=Path(uploaded.name).stem + \"_answered.docx\",\n",
    "                )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}